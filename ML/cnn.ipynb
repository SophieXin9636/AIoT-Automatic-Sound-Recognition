{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image\n",
    "#from PIL import Image \n",
    "#cqt_img = np.array(Image.open(file+\"1_1.png\").convert('L'))\n",
    "#plt.imshow(cqt_img, cmap='gray')\n",
    "#print(cqt_img.shape)\n",
    "#print(cqt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = os.listdir(\"../training_data/training/cqt/np\")\n",
    "label_indices = np.arange(1, len(labels))\n",
    "to_categorical(label_indices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 72 and the array at index 1 has size 96",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b37aed6bc612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \"\"\"\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# loading data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b37aed6bc612>\u001b[0m in \u001b[0;36mget_train_test\u001b[0;34m(split_ratio, random_state)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 72 and the array at index 1 has size 96"
     ]
    }
   ],
   "source": [
    "# Load Image, and save to npy\n",
    "from PIL import Image\n",
    "extension = \".png\"\n",
    "save_path = \"/mnt/hgfs/Linux/soundAnalysis/training_data/training/cqt/np/\"\n",
    "img_path = \"/mnt/hgfs/Linux/soundAnalysis/training_data/correct/cqt/\"\n",
    "\n",
    "def save_data_npy(filename):\n",
    "    cur_file = img_path + filename + extension\n",
    "    cqt_img = np.array(Image.open(cur_file).convert('L')) # Image.open(cur_file).convert('RGB')\n",
    "    cqt_img = np.expand_dims(cqt_img, axis=0)\n",
    "    #plt.imshow(cqt_img)\n",
    "    np.save(save_path + filename, cqt_img)\n",
    "    #print(cqt_img.shape)\n",
    "\n",
    "    \n",
    "### one-hot encoding\n",
    "# Input: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "def get_labels(path=save_path):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(1, len(labels))\n",
    "    # to_categorical: one hot encoding\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "\n",
    "def get_train_test(split_ratio=0.6, random_state=48):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(save_path)\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(save_path + labels[0])\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(save_path + label)\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "    print(X.shape[0], len(y))\n",
    "    assert X.shape[0] == len(y)\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
    "\"\"\"\n",
    "num=1\n",
    "if num==1:\n",
    "    data_path = \"/mnt/hgfs/Linux/soundAnalysis/training_data/correct/cqt/np/\"\n",
    "    img_path  = \"/mnt/hgfs/Linux/soundAnalysis/training_data/correct/cqt/\"\n",
    "elif num==2:\n",
    "    data_path = \"/mnt/hgfs/Linux/soundAnalysis/training_data/incorrect/cqt/np/\"\n",
    "    img_path  = \"/mnt/hgfs/Linux/soundAnalysis/training_data/incorrect/cqt/\"\n",
    "elif num==3:\n",
    "    data_path = \"/mnt/hgfs/Linux/soundAnalysis/training_data/test/cqt/np/\"\n",
    "    img_path  = \"/mnt/hgfs/Linux/soundAnalysis/training_data/test/cqt/\"\n",
    "\n",
    "for sec in range(1,30): # sec\n",
    "    save_data_npy(str(num)+\"_\"+str(sec))\n",
    "\"\"\"\n",
    "# loading data\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "X_train = X_train.reshape(X_train.shape[0], 72, 96, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 72, 96, 1)\n",
    "\n",
    "# one-hot encoding\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_hot.shape)\n",
    "print(y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape = (72,96,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "# FNN layer: 128 output\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# Add output layer\n",
    "model.add(Dense(29, activation='softmax'))\n",
    "# Compile: choose loss function、optimize method\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "# training, 訓練過程會存在 train_history\n",
    "model.fit(X_train, y_train_hot, batch_size=100, epochs=200, verbose=1, validation_data=(X_test, y_test_hot))\n",
    "# 顯示損失函數、訓練成果(分數)\n",
    "score = model.evaluate(X_test, y_test_hot, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 20, 11, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 11, 1)\n",
    "score = model.evaluate(X_test, y_test_hot, verbose=1)\n",
    "\n",
    "# 模型存檔\n",
    "from keras.models import load_model\n",
    "model.save('ASR.h5')  # creates a HDF5 file 'model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "mfcc = wav2mfcc('./soundfile/0601/sound1_1.wav')\n",
    "mfcc_reshaped = mfcc.reshape(1, 20, 11, 1)\n",
    "print(\"labels=\", get_labels())\n",
    "print(\"predict=\", np.argmax(model.predict(mfcc_reshaped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess.py\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "DATA_PATH = \"/mnt/hgfs/Linux/soundAnalysis/training_data/correct/cqt/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image\n",
    "\"\"\"\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(file+\"1_1.png\", target_size = (72, 96))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
